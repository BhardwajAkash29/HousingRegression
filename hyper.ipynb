{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b41a5c49-22d4-4b71-a85d-3489e66b7fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning LinearRegression...\n",
      "Tuning DecisionTree...\n",
      "Best Params for DecisionTree: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Tuning RandomForest...\n",
      "Best Params for RandomForest: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Tuned Model Performance:\n",
      "\n",
      "LinearRegression => MSE: 24.29, R²: 0.6688\n",
      "DecisionTree => MSE: 9.34, R²: 0.8726\n",
      "RandomForest => MSE: 7.90, R²: 0.8923\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset function (include if not defined yet)\n",
    "def load_data():\n",
    "    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "    raw_df = pd.read_csv(data_url, sep=r\"\\s+\", skiprows=22, header=None)\n",
    "    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "    target = raw_df.values[1::2, 2]\n",
    "    feature_names = [\n",
    "        'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE',\n",
    "        'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'\n",
    "    ]\n",
    "    df = pd.DataFrame(data, columns=feature_names)\n",
    "    df['MEDV'] = target\n",
    "    return df\n",
    "\n",
    "# Split function (include if not defined yet)\n",
    "def split_data(df):\n",
    "    X = df.drop('MEDV', axis=1)\n",
    "    y = df['MEDV']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_models(models, X_test, y_test):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        preds = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, preds)\n",
    "        r2 = r2_score(y_test, preds)\n",
    "        results[name] = {'MSE': mse, 'R2': r2}\n",
    "    return results\n",
    "\n",
    "# Parameter grids for tuning\n",
    "def get_param_grids():\n",
    "    grids = {\n",
    "        'LinearRegression': {},  # No hyperparameters for LinearRegression\n",
    "        'DecisionTree': {\n",
    "            'max_depth': [3, 5, 10, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        },\n",
    "        'RandomForest': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [None, 5, 10],\n",
    "            'min_samples_split': [2, 5],\n",
    "        }\n",
    "    }\n",
    "    return grids\n",
    "\n",
    "# GridSearch wrapper function\n",
    "def perform_grid_search(model, param_grid, X_train, y_train):\n",
    "    if param_grid:\n",
    "        grid = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        return grid.best_estimator_, grid.best_params_\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        return model, {}\n",
    "\n",
    "# Tune all models\n",
    "def tune_all_models(X_train, y_train):\n",
    "    base_models = {\n",
    "        'LinearRegression': LinearRegression(),\n",
    "        'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "        'RandomForest': RandomForestRegressor(random_state=42)\n",
    "    }\n",
    "\n",
    "    param_grids = get_param_grids()\n",
    "    best_models = {}\n",
    "\n",
    "    for name, model in base_models.items():\n",
    "        print(f\"Tuning {name}...\")\n",
    "        best_model, best_params = perform_grid_search(model, param_grids[name], X_train, y_train)\n",
    "        if best_params:\n",
    "            print(f\"Best Params for {name}: {best_params}\")\n",
    "        best_models[name] = best_model\n",
    "\n",
    "    return best_models\n",
    "\n",
    "# Run entire hyper tuning pipeline\n",
    "df = load_data()\n",
    "X_train, X_test, y_train, y_test = split_data(df)\n",
    "tuned_models = tune_all_models(X_train, y_train)\n",
    "tuned_results = evaluate_models(tuned_models, X_test, y_test)\n",
    "\n",
    "print(\"\\nTuned Model Performance:\\n\")\n",
    "for name, metrics in tuned_results.items():\n",
    "    print(f\"{name} => MSE: {metrics['MSE']:.2f}, R²: {metrics['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31fa206-3446-4601-97b6-c814b4193660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
